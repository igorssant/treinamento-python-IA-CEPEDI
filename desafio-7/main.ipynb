{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 7 - Classiﬁcação de tweets utilizando o BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar um modelo pré-treinado de PLN (BERT) para classiﬁcar o\n",
    "sentimento de tweets em positivo ou negativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação dos Dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilize um conjunto de dados de avaliações de tweets rotulados com sentimento (positivo/negativo).\n",
    "- Divida o conjunto de dados em conjuntos de treinamento e teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento dos Dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Limpeza e tokenização dos textos dos tweets.\n",
    "- Codiﬁcação dos tokens utilizando o vocabulário do modelo BERT.\n",
    "- Adição de tokens especiais para separar frases e indicar o início e ﬁm do texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning do Modelo BERT:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Carregue o modelo pré-treinado BERT.\n",
    "- Adicione camadas adicionais para a classiﬁcação de sentimento.\n",
    "- Deﬁna a função de perda e o otimizador.\n",
    "- Treine o modelo utilizando o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avalie o modelo utilizando o conjunto de teste.\n",
    "- Calcule a precisão, recall, e outras métricas de avaliação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do Modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teste o modelo com tweets não vistos antes para veriﬁcar sua eﬁcácia na classiﬁcação de sentimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os pacotes necessarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim, tensor, no_grad, max\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o dataset e salvando em uma variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/raw/Twitter_Data.csv\"\n",
    "df_twitter_raw = pd.read_csv(path, sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações sobre os dados contidos no dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores aleatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_raw.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informaçõees detalhadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantidade total de linhas do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"A quantidade total de linhas é: {df_twitter_raw.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA e Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copiando o dataset em nova variável para realizar os tratamentos de forma segura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed = df_twitter_raw.copy(deep = True)\n",
    "df_twitter_processed.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renomeando as colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificando quais são as colunas contidas no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Realizando a renomeação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novas_colunas_nome = [\"texto\", \"emocao\"]\n",
    "df_twitter_processed.columns = novas_colunas_nome\n",
    "df_twitter_processed.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alterando os valores da coluna \"*emocao*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificando os valores atuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed[\"emocao\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores não-númericos/nulos foram achados, vamos tratar isso abaixo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificando os valores não-númericos/nulos na coluna \"*emocao*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed[\"emocao\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificando os valores não-númericos/nulos por todo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como há somente 4 linhas faltantes da coluna \"*texto*\", será optado por excluir completamente as linhas\n",
    "\n",
    "A quantidade de linhas excluidas não irá afetar muito a quantidades de dados do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excluindo as linhas onde há valores não-numéricos/nulos na coluna \"*texto*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed = df_twitter_processed[~df_twitter_processed[\"texto\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nova contagem de valores não-numéricos/nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As linhas onde a coluna \"*emocao*\" possui valores nãp-numéricos/nulos não coincidio com a coluna \"*texto*\".\n",
    "\n",
    "No entanto ainda será optado por excluir as linhas em questão, já que sua quantidade é muito pequena em comparação com o total do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excluindo as linhas onde há valores não-numéricos/nulos na coluna \"*emocao*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed = df_twitter_processed[~df_twitter_processed[\"emocao\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nova contagem de valores não-numéricos/nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos alterar os valores da coluna \"*emocao*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Realizando a alteração dos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emocao_novos_valores = {\n",
    "    -1 : 0, # NEGATIVO\n",
    "    0 : 1,  # NEUTRO\n",
    "    1 : 2   # POSITIVO\n",
    "}\n",
    "\n",
    "df_twitter_processed[\"emocao\"] = df_twitter_processed[\"emocao\"].map(dict_emocao_novos_valores)\n",
    "df_twitter_processed[\"emocao\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alterando os tipos de dados contidos no dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coluna *emocao*:\n",
    "- Atual -> float64\n",
    "- Novo -> uint8\n",
    "\n",
    "Coluna *texto*:\n",
    "- Atual -> Object\n",
    "- Novo -> String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed[\"emocao\"] = df_twitter_processed[\"emocao\"].astype(\"uint8\")\n",
    "df_twitter_processed[\"texto\"] = df_twitter_processed[\"texto\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificando novos tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando dataset atual em formato .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/processed/twitter_data.pkl\"\n",
    "df_twitter_processed.to_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidades unitárias de cada valor único da coluna \"*emocao*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed[\"emocao\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que:\n",
    "- A maioria dos tweets é positivo, com o valor: 72249\n",
    "- A quantidade de tweets neutros é de: 55211\n",
    "- Os tweets negativos são a minoria, com o valor de: 35509"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De forma gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = plt.figure(figsize=(12, 8))\n",
    "plt.hist(x=df_twitter_processed[\"emocao\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desvio Padrão e Média Aritmética"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"O desvio padrão é de: \", df_twitter_processed[\"emocao\"].std(),\n",
    "    \"\\nA média aritmética é de: \", df_twitter_processed[\"emocao\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidade total de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{df_twitter_processed['emocao'].shape[0]} linhas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breve descrição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_processed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando o dataset em dados de entrada (X) e target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_twitter_processed.drop(columns = [\"emocao\"], axis = 1)\n",
    "y = df_twitter_processed[\"emocao\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando a separação de dados de teste e dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando Tokens através do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função para gerar e retornar os tokens através dos dados já separados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizar_texto(array_texto:pd.Series) -> BertTokenizer:\n",
    "    return tokenizer\\\n",
    "        .batch_encode_plus(\n",
    "            array_texto.tolist(),\n",
    "            add_special_tokens = True,\n",
    "            max_length = 512,\n",
    "            return_tensors = \"pt\",\n",
    "            padding = True,\n",
    "            truncation = True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando os tokens através de x_train e x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizar_texto(x_train.iloc[:,0])\n",
    "x_test = tokenizar_texto(x_test.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertendo as listas para Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sequencia = tensor(x_train[\"input_ids\"])\n",
    "x_train_mascara = tensor(x_train[\"attention_mask\"])\n",
    "y_train_tensor = tensor(y_train.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sequencia = tensor(x_test[\"input_ids\"])\n",
    "x_test_mascara = tensor(x_test[\"attention_mask\"])\n",
    "y_test_tensor = tensor(y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader (Carregar os dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tamanho dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a batch size\n",
    "tamanho_batch = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "dados_treino = TensorDataset(\n",
    "    x_train_sequencia, \n",
    "    x_train_mascara,\n",
    "    y_train_tensor\n",
    ")\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(dados_treino)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(\n",
    "    dados_treino,\n",
    "    sampler = train_sampler,\n",
    "    batch_size = tamanho_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap tensors\n",
    "dados_teste = TensorDataset(\n",
    "    x_test_sequencia,\n",
    "    x_test_mascara,\n",
    "    y_test_tensor\n",
    ")\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "test_sampler = SequentialSampler(dados_teste)\n",
    "\n",
    "# dataLoader for validation set\n",
    "test_dataloader = DataLoader(\n",
    "    dados_teste,\n",
    "    sampler = test_sampler,\n",
    "    batch_size = tamanho_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning do modelo BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.classifier = nn.Sequential(\n",
    "    nn.Linear(768, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função de Perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio_perda = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otimizador = optim.Adam(modelo.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidade de Epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_epocas = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(numero_epocas):\n",
    "    modelo.train()\n",
    "    \n",
    "    for passo, batch in enumerate(train_dataloader):\n",
    "        b_input_ids, b_input_mask, b_labels = tuple(t for t in batch)\n",
    "\n",
    "        # Zerar gradientes\n",
    "        criterio_perda.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = modelo(\n",
    "            b_input_ids,\n",
    "            attention_mask = b_input_mask,\n",
    "            labels = b_labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        otimizador.step()\n",
    "\n",
    "        if passo % 100 == 0:\n",
    "            print(f\"==================================================\\nÉpoca: {epoch}\\nPasso: {passo}\\nPerda: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicoes = []\n",
    "valores_reais = []\n",
    "modelo.eval()\n",
    "\n",
    "for idx, batch in enumerate(test_dataloader):\n",
    "    b_input_ids, b_input_mask, b_labels = tuple(t for t in batch)\n",
    "    \n",
    "    with no_grad():\n",
    "        outputs = modelo(\n",
    "            b_input_ids,\n",
    "            attention_mask = b_input_mask\n",
    "        )\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    _, resultados_preditos = max(logits, 1)\n",
    "    \n",
    "    predicoes.extend(resultados_preditos.cpu().numpy())\n",
    "    valores_reais.extend(b_labels.cpu().numpy())\n",
    "\n",
    "acuracia = accuracy_score(valores_reais, predicoes)\n",
    "precisao = precision_score(valores_reais, predicoes)\n",
    "recall = recall_score(valores_reais, predicoes)\n",
    "\n",
    "print(\"Acurácia:\", acuracia)\n",
    "print(\"Precisão:\", precisao)\n",
    "print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cepedi-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

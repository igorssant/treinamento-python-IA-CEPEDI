{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Módulo 3 - Desaﬁo dos Filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar um modelo de Convolutional Neural Network (CNN) capaz deidentiﬁcar faces em imagens.\n",
    "\n",
    "Aqui estão os passos:\n",
    "\n",
    "- Conjunto de Dados:\n",
    "  - Utilize um conjunto de dados robusto, contendo imagens variadas de\n",
    "faces. Divida-o em conjuntos de treinamento e teste.\n",
    "- Pré-processamento:\n",
    "  - Realize pré-processamento nas imagens, incluindo redimensionamento, normalização e eventual aumento de dados para evitar overﬁtting.\n",
    "- Arquitetura da CNN:\n",
    "  - Projete uma arquitetura de CNN adequada para o problema.\n",
    "  - Considere camadas convolucionais, de pooling e totalmente conectadas.\n",
    "  - Experimente arquiteturas conhecidas, como VGG16, ResNet, ou crie a sua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<section>\n",
    "<a>https://www.kaggle.com/code/sifboudjellal/face-recognition-using-cnn</a>\n",
    "<br>\n",
    "<a>https://www.codemag.com/Article/2205081/Implementing-Face-Recognition-Using-Deep-Learning-and-Support-Vector-Machines</a>\n",
    "<br>\n",
    "<a>https://www.youtube.com/watch?v=uqomO_BZ44g</a>\n",
    "</section>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas e pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando os objetos de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treinamento = ImageDataGenerator(rescale = (1 / 255))\n",
    "dados_validacao = ImageDataGenerator(rescale = (1 / 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando as imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caminho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_train = \"datasets/images/train\"\n",
    "path_images_validation = \"datasets/images/validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valor de re-escala das imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devemos re-escalar, pois não temos garantia que:\n",
    "* todas terão o mesmo tamanho,\n",
    "* ou que estaram no mesmo formato (jpeg, png, tiff),\n",
    "* ou que estarão no mesmo canal (rgb, cmyk, P&B, rgba);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nova_escala = (150, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamanho do conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_balote = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando as imagens e salvando em um objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_treinamento = dados_treinamento.flow_from_directory(\n",
    "    path_images_train,\n",
    "    target_size = nova_escala,\n",
    "    batch_size = tamanho_balote,\n",
    "    class_mode = \"binary\"\n",
    ")\n",
    "\n",
    "dataset_validacao = dados_treinamento.flow_from_directory(\n",
    "    path_images_validation,\n",
    "    target_size = nova_escala,\n",
    "    batch_size = tamanho_balote,\n",
    "    class_mode = \"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        activation = \"relu\",\n",
    "        input_shape = (150, 150, 3)\n",
    "    ),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    ####\n",
    "    tf.keras.layers.Conv2D(\n",
    "        128,\n",
    "        (3, 3),\n",
    "        activation = \"relu\",\n",
    "    ),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    ####\n",
    "    tf.keras.layers.Conv2D(\n",
    "        256,\n",
    "        (3, 3),\n",
    "        activation = \"relu\",\n",
    "    ),\n",
    "    tf.keras.layers.MaxPool2D(2, 2),\n",
    "    ####\n",
    "    tf.keras.layers.Flatten(),\n",
    "    ####\n",
    "    tf.keras.layers.Dense(\n",
    "        512,\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    ####\n",
    "    tf.keras.layers.Dense(\n",
    "        1,\n",
    "        activation = \"sigmoid\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.001),\n",
    "    metrics = [tf.keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados para treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximo de iterações e máximo de passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "max_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando tipo do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset_treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As classes do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validacao.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_fit = modelo.fit(\n",
    "    dataset_treinamento,\n",
    "    steps_per_epoch = max_step,\n",
    "    epochs = max_iter,\n",
    "    batch_size = tamanho_balote,\n",
    "    validation_data = dados_validacao\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atestando a qualidade do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caminho para o diretório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_test = \"datasets/images/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validacao.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a qualidade do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for new_image in os.listdir(path_images_test):\n",
    "    curr_img = image.load_img(\n",
    "        path_images_test + new_image,\n",
    "        target_size = nova_escala\n",
    "    )\n",
    "    X = np.expand_dims(\n",
    "        image.img_to_array(curr_img),\n",
    "        axis = 0\n",
    "    )\n",
    "    images = np.vstack([X])\n",
    "    \n",
    "    modelo_predicao = modelo.predict(images)\n",
    "    \n",
    "    if modelo_predicao == 1:\n",
    "        print(\"IT IS NOT A FACE\")\n",
    "    else:\n",
    "        print(\"IT IS A FACE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".aquisicao-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
